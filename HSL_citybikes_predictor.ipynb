{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HSL_citybikes_predictor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/giacomogreggio/HSL-citybikes-predictor/blob/master/HSL_citybikes_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WBjSSe0X0TE6"
      },
      "source": [
        "## Citybike predictor\n",
        "\n",
        "### Elevator pitch\n",
        "Scheduling your day is important for everyone, but every day we have to face problems related to planning your itinerary. When you want to use a citybike to move from a place to another you may find yourself at an empty bike station. Could there be a way to predict the availability? A solution: an application that predicts exactly that based on the time and the weather.\n",
        "\n",
        "\n",
        "### Data: sources, wrangling, management\t\t\n",
        "- The original purpose of the data is not compatible with our needs: the data is meant to describe bike trips/routing, not the bike availability\n",
        "- \n",
        "            \n",
        "### Data analysis: statistics, machine learning\t\n",
        "- We need a predicting model\n",
        "- Predictions for time series: a lot of different variables\n",
        "- Combining different data sources to base the prediction to current situation: weather, time of the day, current bike availability    \n",
        "\n",
        "\n",
        "### Communication of results: summarization & visualization\n",
        "- Finding clear and intuitive way to summarize and visualize data such that it is accessible to the user\n",
        "- \n",
        "            \n",
        "### Operationalization: creating added value, end-user point of view\n",
        "- Mobile optimated web application"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-NNZ_hDaUwh"
      },
      "source": [
        "## Preprocessing the HSL-data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1K5-T3ygWKF"
      },
      "source": [
        "### Initializing everything"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "johv7o6KOQVG",
        "outputId": "fbf701f0-4158-4b54-9af2-2641eb7c04b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "!pip install mpld3"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mpld3 in /usr/local/lib/python3.6/dist-packages (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from mpld3) (3.2.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from mpld3) (2.11.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mpld3) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mpld3) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mpld3) (1.18.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mpld3) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->mpld3) (2.8.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->mpld3) (1.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib->mpld3) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWqTY9JXPUZE"
      },
      "source": [
        "# All imports\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from datetime import datetime\n",
        "from pandas.tseries.offsets import MonthEnd\n",
        "import mpld3\n",
        "from mpld3 import plugins\n",
        "mpld3.enable_notebook()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXb_EGwVFqpg",
        "outputId": "b5602e0c-3974-4df3-d5e7-d133218c1f90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyS9UkKaNlX-"
      },
      "source": [
        "### Data preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF9mpSfOjdfW"
      },
      "source": [
        "def get_station_data():\n",
        "  stations = pd.read_csv(\"/content/drive/My Drive/HSLDataset/Helsingin_ja_Espoon_kaupunkipyöräasemat.csv\")\n",
        "  stations = stations.drop([\"FID\", \"Nimi\", \"Namn\", \"Adress\", \"Kaupunki\", \"Stad\", \"Operaattor\"], axis = 1)\n",
        "  return stations"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP7ZNFmPNxaH"
      },
      "source": [
        "def rate_weather(row):\n",
        "    score = 10\n",
        "    if row['cloud_amount']<2 : score = score\n",
        "    if row['cloud_amount']<5 and row['cloud_amount']>=2 : score = score-1\n",
        "    if row['cloud_amount']<8 and row['cloud_amount']>=5 : score = score-2\n",
        "    if row['cloud_amount']>=8 : score = score-3\n",
        "    if row['visibility']>=40000 : score = score\n",
        "    if row['visibility']>=10000 and row['visibility']<40000 :  score = score-1\n",
        "    if row['visibility']<10000 :  score = score-2\n",
        "    if row['rain_intensity']<=0.25 :  score = score\n",
        "    if row['rain_intensity']<=1 and row['rain_intensity']>0.25: score = score-1   \n",
        "    if row['rain_intensity']<=4 and row['rain_intensity']>1: score = score-2\n",
        "    if row['rain_intensity']<=16 and row['rain_intensity']>4: score = score-3\n",
        "    if row['rain_intensity']>16: score = score-4   \n",
        "    if row['wind_speed']<=1.5: score = score   \n",
        "    if row['wind_speed']<=3.3 and row['wind_speed']>1.5: score = score-1\n",
        "    if row['wind_speed']<=8 and row['wind_speed']>3.3: score = score-2\n",
        "    if row['wind_speed']>8: score = score-3\n",
        "    if score<1 : score = 1\n",
        "    return(score)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzSXlXTMlqK6"
      },
      "source": [
        "def get_weather_data():\n",
        "  filepath ='/content/drive/My Drive/HSLDataset/bikeweather_2019.csv'\n",
        "  df = pd.read_csv(filepath)\n",
        "  df = df.rename(\n",
        "      columns={\n",
        "      'Vuosi': 'year', 'Kk': 'month', 'Pv': 'day', 'Klo': 'time', 'Aikavyöhyke': 'timezone', 'Pilvien määrä (1/8)': 'cloud_amount',\n",
        "      'Ilmanpaine (msl) (hPa)': 'pressure', 'Suhteellinen kosteus (%)': 'rel_humidity', 'Sateen intensiteetti (mm/h)': 'rain_intensity',\n",
        "      'Lumensyvyys (cm)': 'snow_depth', 'Ilman lämpötila (degC)': 'air_temp', 'Kastepistelämpötila (degC)': 'dew-point_temp',\n",
        "      'Näkyvyys (m)': 'visibility', 'Tuulen suunta (deg)': 'wind_dir', 'Puuskanopeus (m/s)': 'gust_speed', 'Tuulen nopeus (m/s)': 'wind_speed'\n",
        "      }\n",
        "  )\n",
        "  df = df.drop(['pressure', 'rel_humidity', 'snow_depth', 'dew-point_temp', 'wind_dir', 'gust_speed'], axis=1)\n",
        "  df['datetime']=pd.to_datetime(df.year.astype(str)+'-'+df.month.astype(str)+'-'+df.day.astype(str)+' '+df.time.astype(str))\n",
        "  df['weather_rate'] = df.apply(lambda row: rate_weather(row), axis=1)\n",
        "  return df  "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gl-W9W0PginX"
      },
      "source": [
        "def preprocess_month(month):\n",
        "  path = \"/content/drive/My Drive/HSLDataset/od-trips-2019/\"\n",
        "  extension = \".csv\"\n",
        "  filename = \"2019-\" + '{:02.0f}'.format(month)\n",
        "  full_path = path + filename + extension\n",
        "  \n",
        "  data = pd.read_csv(full_path, sep = \",\")\n",
        "\n",
        "  # Make time a datetime object to ease handling. Also floor to starting hour\n",
        "  data[\"Dep date\"] = pd.to_datetime(data[\"Departure\"], errors = \"ignore\").dt.floor(freq = \"H\")\n",
        "  data[\"Return date\"] = pd.to_datetime(data[\"Return\"], errors = \"ignore\").dt.floor(freq = \"H\")\n",
        "\n",
        "  # For our analysis we shouldn't need this information\n",
        "  data = data.drop(columns=[\"Covered distance (m)\", \"Duration (sec.)\", \"Departure\", \"Return\"])\n",
        "\n",
        "  # Get the outgoing bikes per station at timeframe\n",
        "  outgoing = data.groupby(\"Departure station id\")[\"Dep date\"].value_counts()\n",
        "  outgoing = outgoing.sort_index()\n",
        "  outgoing = outgoing.rename_axis(index = {\"Dep date\" : \"Date\", \"Departure station id\" : \"ID\"})\n",
        "  outgoing = outgoing.rename(\"Outgoing\")\n",
        "\n",
        "  # Get the arriving bikes per station at timeframe\n",
        "  arriving = data.groupby(\"Return station id\")[\"Return date\"].value_counts()\n",
        "  arriving = arriving.sort_index()\n",
        "  arriving = arriving.rename_axis(index = {\"Return date\" : \"Date\", \"Return station id\" : \"ID\"})\n",
        "  arriving = arriving.rename(\"Arriving\")\n",
        "\n",
        "  outgoing_arriving_merge = pd.merge(outgoing, arriving, on = [\"ID\", \"Date\"], how = \"outer\")\n",
        "  outgoing_arriving_merge = outgoing_arriving_merge.fillna(0)\n",
        "\n",
        "  \n",
        "  stations = set(outgoing_arriving_merge.index.get_level_values(0))\n",
        "\n",
        "  # We need data for ALL timeframes\n",
        "  first_day_of_month = \"2019-\" + '{:02.0f}'.format(month) + \"-01 00:00:00\"\n",
        "  last_day_of_month = pd.Timestamp(\"2019-\" + '{:02.0f}'.format(month) + \"-01 23:00:00\") + MonthEnd(0)\n",
        "  all_dates = pd.date_range(first_day_of_month, last_day_of_month, freq = \"H\")\n",
        "  idx = pd.MultiIndex.from_product([stations, all_dates], names = [\"ID\", \"Date\"])\n",
        "  mega_frame_with_station_date_cartesian_product = pd.DataFrame(index = idx)\n",
        "  processed = pd.merge(mega_frame_with_station_date_cartesian_product, outgoing_arriving_merge, on = [\"ID\", \"Date\"], how = \"left\")\n",
        "  processed = processed.fillna(0)\n",
        "  processed = processed.reset_index()\n",
        "\n",
        "  # Merge with the station data from HSL\n",
        "  station_data = get_station_data()\n",
        "  processed_with_station_data = pd.merge(processed, station_data, on = \"ID\", how = \"inner\")\n",
        "\n",
        "  processed_with_station_data.to_csv(\"./drive/My Drive/HSLDataset/processed/\" + filename + \"-processed.csv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WdXseBI7hTGS"
      },
      "source": [
        "def process_and_write_raw_data():\n",
        "  # Process all the data and save them as csv-files\n",
        "  for month in range(4,11):\n",
        "    data = preprocess_month(month)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5Ub3j_CoszK"
      },
      "source": [
        "#### Merging functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bqa08qodOc98"
      },
      "source": [
        "def drop_columns_weather(df):\n",
        "  return df.drop(columns=['year','month','day','time','timezone','cloud_amount','rain_intensity','air_temp','visibility','wind_speed'])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VusPcEpjD9Hq"
      },
      "source": [
        "def drop_columns_bikes(df):\n",
        "  bikes = df.drop(columns=['Osoite','Kapasiteet','x','y'])\n",
        "  bikes = bikes.rename(columns={'Date':'datetime', 'Outgoing':'departures', 'Arriving':'arrivals','ID':'station_id','Name':'station_name'})\n",
        "  return bikes"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDauVE3DNgFC"
      },
      "source": [
        "# Merging on datetime column: the column must be named 'datetime' in both tables\n",
        "def merge_tables(df1, df2):\n",
        "  merged = df1.merge(\n",
        "    df2,\n",
        "    how='inner',\n",
        "    on='datetime'\n",
        "  )\n",
        "  return merged"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PadPXPXwow8y"
      },
      "source": [
        "#### Getters for data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JcDGv5K9f02p"
      },
      "source": [
        "def get_processed_data_for_month(month):\n",
        "  month = '{:02.0f}'.format(month)\n",
        "  data = pd.read_csv(\"/content/drive/My Drive/HSLDataset/processed/2019-\" + month + \"-processed.csv\")\n",
        "  data[\"Date\"] = pd.to_datetime(data[\"Date\"])\n",
        "  \n",
        "  # Don't know what this is all about but I guess everything is fine-ish :DDD\n",
        "  data = data.drop(\"Unnamed: 0\", axis = 1)\n",
        "\n",
        "  data[\"weekday\"] = data[\"Date\"].dt.weekday\n",
        "  return data"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2f6j90WrlRS0"
      },
      "source": [
        "def merge_all_data_and_write():\n",
        "  # Get the already processed data for all the months\n",
        "  data_april = get_processed_data_for_month(4)\n",
        "  data_may = get_processed_data_for_month(5)\n",
        "  data_june = get_processed_data_for_month(6)\n",
        "  data_july = get_processed_data_for_month(7)\n",
        "  data_august = get_processed_data_for_month(8)\n",
        "  data_september = get_processed_data_for_month(9)\n",
        "  data_october = get_processed_data_for_month(10)\n",
        "\n",
        "  # Concatanate the trip count data of the months\n",
        "  big_boi = pd.concat([data_april, data_may, data_june, data_july, data_august, data_september, data_october])\n",
        "\n",
        "  # Merge the weather data\n",
        "  weather_data = get_weather_data()\n",
        "  merged_megaset = merge_tables(drop_columns_bikes(big_boi),drop_columns_weather(weather_data))\n",
        "\n",
        "  merged_megaset.to_csv(\"./drive/My Drive/HSLDataset/processed/whole_data-processed.csv\", index = False)\n",
        "  return merged_megaset"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lImMNQLhs1zY"
      },
      "source": [
        "def get_all_data():\n",
        "  data = pd.read_csv(\"./drive/My Drive/HSLDataset/processed/whole_data-processed.csv\")\n",
        "  data[\"datetime\"] =pd.to_datetime(data[\"datetime\"])\n",
        "  return data"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aThMDl9mPGz0"
      },
      "source": [
        "## Looking at the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A13dqniFpRxt"
      },
      "source": [
        "### Getter functions for specific subsets of data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBzFIEfuRFdw"
      },
      "source": [
        "def data_of_station_for_weekdays_in_month(dataframe, station, month, weekday):\n",
        "  station_data = dataframe[dataframe[\"station_id\"] == station]\n",
        "  station_data_for_month = station_data[(station_data[\"datetime\"].dt.month == month) & (station_data[\"datetime\"].dt.weekday == weekday)]\n",
        "  return station_data_for_month"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gP1lEm89pZhO"
      },
      "source": [
        "### Test area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMP9TdEDuQBu"
      },
      "source": [
        "all_data = get_all_data()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmVwe_yjh2GI"
      },
      "source": [
        "## Different data visualizations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09TH09GGQVds",
        "outputId": "b4515e7a-6b21-4b76-dbf5-35e2c157c7a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "source": [
        "wanted_data = data_of_station_for_weekdays_in_month(all_data, 19, 9, 6)\n",
        "weekday_occurences = set(wanted_data[\"datetime\"].dt.date)\n",
        "fig, axs = plt.subplots(1, len(weekday_occurences), figsize = (30,6))\n",
        "\n",
        "\n",
        "for idx,weekday_occurence in enumerate(weekday_occurences):\n",
        "  weekday_occurence_data = wanted_data[wanted_data[\"datetime\"].dt.date == weekday_occurence]\n",
        "  axs[idx].grid(True, alpha = 0.3)\n",
        "  axs[idx].plot(weekday_occurence_data[\"datetime\"].dt.hour, weekday_occurence_data[\"departures\"], 'r', weekday_occurence_data[\"datetime\"].dt.hour, weekday_occurence_data[\"arrivals\"], 'b', alpha = 0.3)\n",
        "  axs[idx].title.set_text(weekday_occurence)\n",
        "mpld3.display()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-2bf2fca7ee42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mwanted_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_of_station_for_weekdays_in_month\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mweekday_occurences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwanted_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweekday_occurences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-c48cc1371f2f>\u001b[0m in \u001b[0;36mdata_of_station_for_weekdays_in_month\u001b[0;34m(dataframe, station, month, weekday)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdata_of_station_for_weekdays_in_month\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweekday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mstation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"station_id\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mstation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mstation_data_for_month\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mmonth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstation_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"datetime\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweekday\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mweekday\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mstation_data_for_month\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5268\u001b[0m             \u001b[0;32mor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5269\u001b[0m         ):\n\u001b[0;32m-> 5270\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5271\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/accessor.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, cls)\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;31m# we're accessing the attribute of the class, i.e., Dataset.geo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0maccessor_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_accessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m         \u001b[0;31m# Replace the property with the accessor object. Inspired by:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;31m# http://www.pydanny.com/cached-property.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/core/indexes/accessors.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, data)\u001b[0m\n\u001b[1;32m    336\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mDatetimeProperties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 338\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can only use .dt accessor with datetimelike values\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: Can only use .dt accessor with datetimelike values"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEXizP2I3gAs",
        "outputId": "d54697bb-f097-462f-8179-b8c5f559ab6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "all_data[\"datetime\"].dt"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pandas.core.indexes.accessors.DatetimeProperties object at 0x7f5d1d5c8588>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    }
  ]
}